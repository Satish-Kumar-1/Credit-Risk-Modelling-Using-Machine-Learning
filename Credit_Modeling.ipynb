{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satish-Kumar-1/Credit-Risk-Modelling-Using-Machine-Learning/blob/main/Credit_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqydn_vaVOic",
        "outputId": "9c814743-432a-471c-ef8c-80d0b2b0cf8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgfT3bjur004"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import chi2_contingency\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I76a73Y9sIhT"
      },
      "outputs": [],
      "source": [
        "a1 = pd.read_excel(\"/content/drive/MyDrive/case_study1.xlsx\")\n",
        "a2 = pd.read_excel(\"/content/drive/MyDrive/case_study2.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU6wk21BsVAX"
      },
      "outputs": [],
      "source": [
        "df1 = a1.copy()\n",
        "df2 = a2.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKIjxX8sdIAx",
        "outputId": "33978f61-fb2a-4c69-ae60-9af90b30207e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(51336, 26) (51336, 62)\n"
          ]
        }
      ],
      "source": [
        "print(df1.shape, df2.shape) ## (51336, 26), (51336, 62)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDw8ra-6dbpc"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Removing the rows having null values in Age column\n",
        "df1 = df1.loc[df1['Age_Newest_TL'] != -99999]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLqzrAmKx02x",
        "outputId": "691e8b2e-ed29-488e-ba2c-967d3ae95715"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(51296, 26)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CffagsPaeaWi"
      },
      "outputs": [],
      "source": [
        "columns_with_null_values_df2 = []\n",
        "\n",
        "for i in df2.columns:\n",
        "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
        "        columns_with_null_values_df2.append(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohcSOtdleqq0"
      },
      "outputs": [],
      "source": [
        "## Dropping columns having null values\n",
        "df2 = df2.drop(columns_with_null_values_df2, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFG2aapAf8Z4",
        "outputId": "0e007400-597a-4fb8-9187-67e0deec31f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(51336, 54)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhc2tz-ugEbl"
      },
      "outputs": [],
      "source": [
        "## Dropping rows having null values\n",
        "for i in df2.columns:\n",
        "    df2 = df2.loc[df2[i] != -99999]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GUc6zbH19PS",
        "outputId": "39f6cd31-861a-43ac-88b6-634315901027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(51296, 26) (42066, 54)\n"
          ]
        }
      ],
      "source": [
        "print(df1.shape, df2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSRmyiN3gY8q",
        "outputId": "31591286-db47-45ef-e23d-e8129d8635f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROSPECTID\n"
          ]
        }
      ],
      "source": [
        "## Check Common columns\n",
        "for i in list(df1.columns):\n",
        "    if i in list(df2.columns):\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcZ_ljK-gdZj"
      },
      "outputs": [],
      "source": [
        "## Merge the dataframes 1 and 2 using inner join\n",
        "\n",
        "df = pd.merge(df1, df2, how = 'inner', left_on = ['PROSPECTID'],right_on = ['PROSPECTID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8CZ1VbLnxWM",
        "outputId": "0355f781-0046-4592-f009-0c97baba2321"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42064, 79)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx_iW3K1ntRt"
      },
      "outputs": [],
      "source": [
        "## Now we check how many columns are categorical\n",
        "l = []\n",
        "for i in df.columns:\n",
        "    if df[i].dtype == 'object':\n",
        "        l.append(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Nyx1ItobQ2",
        "outputId": "7f3ac93b-c722-4568-c35e-3786d513cc28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5YvuJAooDbV",
        "outputId": "bd6ae161-9c7c-43cc-9c68-db09aacc4618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MARITALSTATUS _____ 3.578180861038862e-233\n",
            "EDUCATION _____ 2.6942265249737532e-30\n",
            "GENDER _____ 1.907936100186563e-05\n",
            "last_prod_enq2 _____ 0.0\n",
            "first_prod_enq2 _____ 7.84997610555419e-287\n"
          ]
        }
      ],
      "source": [
        "## Chi-square test to check the association of columns having categorial values with the Approved flag\n",
        "\n",
        "for i in l[0:5]:\n",
        "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i],df['Approved_Flag']))\n",
        "    print(i, '_____', pval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB_oSAuAoza_"
      },
      "outputs": [],
      "source": [
        "## Check the multicollinearity between features in df\n",
        "## For this we calculate the VIF value and drop the columns whose VIF > 6\n",
        "\n",
        "# VIF for numrical columns\n",
        "\n",
        "numeric_columns = []\n",
        "for i in df.columns:\n",
        "    if df[i].dtype != 'object' and i not in ['PROSPECTID', 'Approved_Flag']:\n",
        "        numeric_columns.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5mRxvF6-QmM",
        "outputId": "80a82f7e-6aeb-4e92-f3ab-76049526a5fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 -------- inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 -------- inf\n",
            "0 -------- 11.320180023967996\n",
            "0 -------- 8.363698035000336\n",
            "0 -------- 6.520647877790928\n",
            "0 -------- 5.149501618212625\n",
            "1 -------- 2.611111040579735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 -------- inf\n",
            "2 -------- 1788.7926256209232\n",
            "2 -------- 8.601028256477228\n",
            "2 -------- 3.832800792153077\n",
            "3 -------- 6.099653381646723\n",
            "3 -------- 5.581352009642766\n",
            "4 -------- 1.985584353098778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 -------- inf\n",
            "5 -------- 4.80953830281934\n",
            "6 -------- 23.270628983464636\n",
            "6 -------- 30.595522588100053\n",
            "6 -------- 4.384346405965583\n",
            "7 -------- 3.0646584155234238\n",
            "8 -------- 2.898639771299251\n",
            "9 -------- 4.377876915347324\n",
            "10 -------- 2.207853583695844\n",
            "11 -------- 4.916914200506864\n",
            "12 -------- 5.214702030064725\n",
            "13 -------- 3.3861625024231476\n",
            "14 -------- 7.840583309478997\n",
            "14 -------- 5.255034641721434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15 -------- inf\n",
            "15 -------- 7.380634506427238\n",
            "15 -------- 1.4210050015175733\n",
            "16 -------- 8.083255010190316\n",
            "16 -------- 1.6241227524040114\n",
            "17 -------- 7.257811920140003\n",
            "17 -------- 15.59624383268298\n",
            "17 -------- 1.825857047132431\n",
            "18 -------- 1.5080839450032664\n",
            "19 -------- 2.172088834824578\n",
            "20 -------- 2.6233975535272274\n",
            "21 -------- 2.2959970812106176\n",
            "22 -------- 7.360578319196446\n",
            "22 -------- 2.1602387773102567\n",
            "23 -------- 2.8686288267891467\n",
            "24 -------- 6.458218003637272\n",
            "24 -------- 2.8474118865638247\n",
            "25 -------- 4.753198156284083\n",
            "26 -------- 16.22735475594825\n",
            "26 -------- 6.424377256363877\n",
            "26 -------- 8.887080381808678\n",
            "26 -------- 2.3804746142952653\n",
            "27 -------- 8.60951347651454\n",
            "27 -------- 13.06755093547673\n",
            "27 -------- 3.500040056654653\n",
            "28 -------- 1.9087955874813773\n",
            "29 -------- 17.006562234161628\n",
            "29 -------- 10.730485153719197\n",
            "29 -------- 2.3538497522950275\n",
            "30 -------- 22.10485591513649\n",
            "30 -------- 2.7971639638512924\n",
            "31 -------- 3.424171203217696\n",
            "32 -------- 10.175021454450922\n",
            "32 -------- 6.408710354561292\n",
            "32 -------- 1.001151196262563\n",
            "33 -------- 3.069197305397273\n",
            "34 -------- 2.8091261600643724\n",
            "35 -------- 20.249538381980678\n",
            "35 -------- 15.864576541593774\n",
            "35 -------- 1.833164974053215\n",
            "36 -------- 1.5680839909542046\n",
            "37 -------- 1.9307572353811682\n",
            "38 -------- 4.331265056645244\n",
            "39 -------- 9.390334396150173\n"
          ]
        }
      ],
      "source": [
        "## VIF sequentially check\n",
        "\n",
        "vif_data = df[numeric_columns]\n",
        "total_columns = vif_data.shape[1]\n",
        "columns_to_be_kept = []\n",
        "column_index = 0\n",
        "\n",
        "for i in range(0, total_columns):\n",
        "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
        "    print(column_index, '--------' , vif_value)\n",
        "\n",
        "    if vif_value <=6:\n",
        "        columns_to_be_kept.append(numeric_columns[i])\n",
        "        column_index = column_index + 1\n",
        "\n",
        "    else:\n",
        "        vif_data = vif_data.drop([numeric_columns[i]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNBeUisuCnOu",
        "outputId": "9b7b9e83-5462-41bb-a39f-55fea32315db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42064, 79)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIsboFqxDBCU",
        "outputId": "ea99cf91-3631-4f68-f29e-0c813456ab6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(columns_to_be_kept)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5gxxf8xDX0y"
      },
      "outputs": [],
      "source": [
        "## Now we check Anova for columns_to_be_kept\n",
        "\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "columns_to_be_kept_numerical = []\n",
        "\n",
        "for i in columns_to_be_kept:\n",
        "    a = list(df[i])\n",
        "    b = list(df['Approved_Flag'])\n",
        "\n",
        "    group_P1 =[value for value , group in zip(a, b) if group == 'P1']\n",
        "    group_P2 =[value for value , group in zip(a, b) if group == 'P2']\n",
        "    group_P3 =[value for value , group in zip(a, b) if group == 'P3']\n",
        "    group_P4 =[value for value , group in zip(a, b) if group == 'P4']\n",
        "\n",
        "    f_statistics, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
        "\n",
        "    if p_value <= 0.05:\n",
        "        columns_to_be_kept_numerical.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxmBH6PgFFUj"
      },
      "outputs": [],
      "source": [
        "features = columns_to_be_kept_numerical  + l[0:5]\n",
        "df = df[features + ['Approved_Flag']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXH-q45_7Epb",
        "outputId": "1b37c524-46b3-4eab-ee5d-6fd78ce5186f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Married' 'Single']\n",
            "['12TH' 'GRADUATE' 'SSC' 'POST-GRADUATE' 'UNDER GRADUATE' 'OTHERS'\n",
            " 'PROFESSIONAL']\n",
            "['M' 'F']\n",
            "['PL' 'ConsumerLoan' 'AL' 'CC' 'others' 'HL']\n",
            "['PL' 'ConsumerLoan' 'others' 'AL' 'HL' 'CC']\n",
            "['P2' 'P1' 'P3' 'P4']\n"
          ]
        }
      ],
      "source": [
        "## There are some categorical features, so lets do encoding\n",
        "\n",
        "for col in l:\n",
        "    print(df[col].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOfhqo987HZJ"
      },
      "outputs": [],
      "source": [
        "## Lable encoding to education\n",
        "\n",
        "df.loc[df['EDUCATION'] == 'SSC', ['EDUCATION']] = 1\n",
        "df.loc[df['EDUCATION'] == '12TH', ['EDUCATION']] = 2\n",
        "df.loc[df['EDUCATION'] == 'GRADUATE', ['EDUCATION']] = 3\n",
        "df.loc[df['EDUCATION'] == 'UNDER GRADUATE', ['EDUCATION']] = 3\n",
        "df.loc[df['EDUCATION'] == 'POST-GRADUATE', ['EDUCATION']] = 4\n",
        "df.loc[df['EDUCATION'] == 'OTHERS', ['EDUCATION']] = 1\n",
        "df.loc[df['EDUCATION'] == 'PROFESSIONAL', ['EDUCATION']] = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7a3OWW1SRS2",
        "outputId": "1a102b27-0f33-404f-9ca9-20a9d96f2c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EDUCATION\n",
            "3    18931\n",
            "2    11703\n",
            "1     9532\n",
            "4     1898\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df['EDUCATION'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j5hEqTqSXMX",
        "outputId": "71f9987f-45b5-4405-f443-98e2e6312f7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42064 entries, 0 to 42063\n",
            "Data columns (total 43 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   pct_tl_open_L6M            42064 non-null  float64\n",
            " 1   pct_tl_closed_L6M          42064 non-null  float64\n",
            " 2   Tot_TL_closed_L12M         42064 non-null  int64  \n",
            " 3   pct_tl_closed_L12M         42064 non-null  float64\n",
            " 4   Tot_Missed_Pmnt            42064 non-null  int64  \n",
            " 5   CC_TL                      42064 non-null  int64  \n",
            " 6   Home_TL                    42064 non-null  int64  \n",
            " 7   PL_TL                      42064 non-null  int64  \n",
            " 8   Secured_TL                 42064 non-null  int64  \n",
            " 9   Unsecured_TL               42064 non-null  int64  \n",
            " 10  Other_TL                   42064 non-null  int64  \n",
            " 11  Age_Oldest_TL              42064 non-null  int64  \n",
            " 12  Age_Newest_TL              42064 non-null  int64  \n",
            " 13  time_since_recent_payment  42064 non-null  int64  \n",
            " 14  max_recent_level_of_deliq  42064 non-null  int64  \n",
            " 15  num_deliq_6_12mts          42064 non-null  int64  \n",
            " 16  num_times_60p_dpd          42064 non-null  int64  \n",
            " 17  num_std_12mts              42064 non-null  int64  \n",
            " 18  num_sub                    42064 non-null  int64  \n",
            " 19  num_sub_6mts               42064 non-null  int64  \n",
            " 20  num_sub_12mts              42064 non-null  int64  \n",
            " 21  num_dbt                    42064 non-null  int64  \n",
            " 22  num_dbt_12mts              42064 non-null  int64  \n",
            " 23  num_lss                    42064 non-null  int64  \n",
            " 24  recent_level_of_deliq      42064 non-null  int64  \n",
            " 25  CC_enq_L12m                42064 non-null  int64  \n",
            " 26  PL_enq_L12m                42064 non-null  int64  \n",
            " 27  time_since_recent_enq      42064 non-null  int64  \n",
            " 28  enq_L3m                    42064 non-null  int64  \n",
            " 29  NETMONTHLYINCOME           42064 non-null  int64  \n",
            " 30  Time_With_Curr_Empr        42064 non-null  int64  \n",
            " 31  CC_Flag                    42064 non-null  int64  \n",
            " 32  PL_Flag                    42064 non-null  int64  \n",
            " 33  pct_PL_enq_L6m_of_ever     42064 non-null  float64\n",
            " 34  pct_CC_enq_L6m_of_ever     42064 non-null  float64\n",
            " 35  HL_Flag                    42064 non-null  int64  \n",
            " 36  GL_Flag                    42064 non-null  int64  \n",
            " 37  MARITALSTATUS              42064 non-null  object \n",
            " 38  EDUCATION                  42064 non-null  object \n",
            " 39  GENDER                     42064 non-null  object \n",
            " 40  last_prod_enq2             42064 non-null  object \n",
            " 41  first_prod_enq2            42064 non-null  object \n",
            " 42  Approved_Flag              42064 non-null  object \n",
            "dtypes: float64(5), int64(32), object(6)\n",
            "memory usage: 13.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_hfjj-mTGJM"
      },
      "outputs": [],
      "source": [
        "## Some columns are still of type object\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns= ['MARITALSTATUS' , 'GENDER' , 'last_prod_enq2', 'first_prod_enq2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYJWgmQRTMDm",
        "outputId": "9452873e-00b8-46f6-8f13-2b8ee34e4280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42064 entries, 0 to 42063\n",
            "Data columns (total 55 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   pct_tl_open_L6M               42064 non-null  float64\n",
            " 1   pct_tl_closed_L6M             42064 non-null  float64\n",
            " 2   Tot_TL_closed_L12M            42064 non-null  int64  \n",
            " 3   pct_tl_closed_L12M            42064 non-null  float64\n",
            " 4   Tot_Missed_Pmnt               42064 non-null  int64  \n",
            " 5   CC_TL                         42064 non-null  int64  \n",
            " 6   Home_TL                       42064 non-null  int64  \n",
            " 7   PL_TL                         42064 non-null  int64  \n",
            " 8   Secured_TL                    42064 non-null  int64  \n",
            " 9   Unsecured_TL                  42064 non-null  int64  \n",
            " 10  Other_TL                      42064 non-null  int64  \n",
            " 11  Age_Oldest_TL                 42064 non-null  int64  \n",
            " 12  Age_Newest_TL                 42064 non-null  int64  \n",
            " 13  time_since_recent_payment     42064 non-null  int64  \n",
            " 14  max_recent_level_of_deliq     42064 non-null  int64  \n",
            " 15  num_deliq_6_12mts             42064 non-null  int64  \n",
            " 16  num_times_60p_dpd             42064 non-null  int64  \n",
            " 17  num_std_12mts                 42064 non-null  int64  \n",
            " 18  num_sub                       42064 non-null  int64  \n",
            " 19  num_sub_6mts                  42064 non-null  int64  \n",
            " 20  num_sub_12mts                 42064 non-null  int64  \n",
            " 21  num_dbt                       42064 non-null  int64  \n",
            " 22  num_dbt_12mts                 42064 non-null  int64  \n",
            " 23  num_lss                       42064 non-null  int64  \n",
            " 24  recent_level_of_deliq         42064 non-null  int64  \n",
            " 25  CC_enq_L12m                   42064 non-null  int64  \n",
            " 26  PL_enq_L12m                   42064 non-null  int64  \n",
            " 27  time_since_recent_enq         42064 non-null  int64  \n",
            " 28  enq_L3m                       42064 non-null  int64  \n",
            " 29  NETMONTHLYINCOME              42064 non-null  int64  \n",
            " 30  Time_With_Curr_Empr           42064 non-null  int64  \n",
            " 31  CC_Flag                       42064 non-null  int64  \n",
            " 32  PL_Flag                       42064 non-null  int64  \n",
            " 33  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
            " 34  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
            " 35  HL_Flag                       42064 non-null  int64  \n",
            " 36  GL_Flag                       42064 non-null  int64  \n",
            " 37  EDUCATION                     42064 non-null  object \n",
            " 38  Approved_Flag                 42064 non-null  object \n",
            " 39  MARITALSTATUS_Married         42064 non-null  bool   \n",
            " 40  MARITALSTATUS_Single          42064 non-null  bool   \n",
            " 41  GENDER_F                      42064 non-null  bool   \n",
            " 42  GENDER_M                      42064 non-null  bool   \n",
            " 43  last_prod_enq2_AL             42064 non-null  bool   \n",
            " 44  last_prod_enq2_CC             42064 non-null  bool   \n",
            " 45  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
            " 46  last_prod_enq2_HL             42064 non-null  bool   \n",
            " 47  last_prod_enq2_PL             42064 non-null  bool   \n",
            " 48  last_prod_enq2_others         42064 non-null  bool   \n",
            " 49  first_prod_enq2_AL            42064 non-null  bool   \n",
            " 50  first_prod_enq2_CC            42064 non-null  bool   \n",
            " 51  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
            " 52  first_prod_enq2_HL            42064 non-null  bool   \n",
            " 53  first_prod_enq2_PL            42064 non-null  bool   \n",
            " 54  first_prod_enq2_others        42064 non-null  bool   \n",
            "dtypes: bool(16), float64(5), int64(32), object(2)\n",
            "memory usage: 13.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df_encoded.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXu7lUchUxJX"
      },
      "source": [
        "PREPROCESSING TO FIT THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSwuJQ0EUoGc"
      },
      "outputs": [],
      "source": [
        "x = df_encoded.drop(['Approved_Flag'], axis = 1)\n",
        "y = df_encoded['Approved_Flag']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlNBRvuxY4mm"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeGAafYybepV"
      },
      "source": [
        "# Random Forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "8I9RLPvhZT0_",
        "outputId": "c9f78790-a2df-4add-da65-f7d6e92834a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=42)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state = 42)\n",
        "rf_classifier.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAe0jI3bZjzT"
      },
      "outputs": [],
      "source": [
        "y_pred = rf_classifier.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H-0WHkvZ4iE",
        "outputId": "32f369e8-87f8-448d-ddfb-c52e148fe357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is:  0.7636990372043266\n"
          ]
        }
      ],
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy is: ', acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIkkOXjbabvc",
        "outputId": "fb9a7af2-6920-4ed9-9f57-80c560a6ba47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLass p1: \n",
            "Precision: 0.8370457209847597\n",
            "Recall: 0.7041420118343196\n",
            "F1 Score: 0.7648634172469203\n",
            "\n",
            "CLass p2: \n",
            "Precision: 0.7957519116397621\n",
            "Recall: 0.9282457879088206\n",
            "F1 Score: 0.8569075937785909\n",
            "\n",
            "CLass p3: \n",
            "Precision: 0.4423380726698262\n",
            "Recall: 0.21132075471698114\n",
            "F1 Score: 0.28600612870275793\n",
            "\n",
            "CLass p4: \n",
            "Precision: 0.7178502879078695\n",
            "Recall: 0.7269193391642371\n",
            "F1 Score: 0.7223563495895703\n",
            "\n"
          ]
        }
      ],
      "source": [
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "for i, v in enumerate(['p1' , 'p2' , 'p3' , 'p4']):\n",
        "    print(f\"CLass {v}: \")\n",
        "    print(f\"Precision: {precision[i]}\")\n",
        "    print(f\"Recall: {recall[i]}\")\n",
        "    print(f\"F1 Score: {f1_score[i]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNBVawwNb05B"
      },
      "source": [
        "# XGboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-s307_ybRun"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcnwSeCocKMH"
      },
      "outputs": [],
      "source": [
        "xgb_classifier = xgb.XGBClassifier(objective = 'multi:Softmax', num_classes = 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91uaZofcBWHI"
      },
      "outputs": [],
      "source": [
        "df_encoded['EDUCATION'] = df_encoded['EDUCATION'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "MKPYvUD5ccPK",
        "outputId": "7ae609c7-b878-4ef6-8050-aabe50afd486"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [03:41:00] WARNING: /workspace/src/learner.cc:742: \n",
            "Parameters: { \"num_classes\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_classes=4, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_classes=4, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_classes=4, num_parallel_tree=None, ...)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df_encoded['Approved_Flag']\n",
        "x = df_encoded.drop(['Approved_Flag'],  axis = 1)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x , y_encoded, test_size = 0.2, random_state = 42)\n",
        "xgb_classifier.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDunyKZtdYmA"
      },
      "outputs": [],
      "source": [
        "y_pred = xgb_classifier.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXvzwdTfdw9B",
        "outputId": "78faf7ca-064a-407f-8658-30d32c1b0fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is:  0.7783192677998336\n",
            "CLass p1: \n",
            "Precision: 0.823906083244397\n",
            "Recall: 0.7613412228796844\n",
            "F1 Score: 0.7913890312660173\n",
            "\n",
            "CLass p2: \n",
            "Precision: 0.8255418233924413\n",
            "Recall: 0.913577799801784\n",
            "F1 Score: 0.8673315769665036\n",
            "\n",
            "CLass p3: \n",
            "Precision: 0.4756380510440835\n",
            "Recall: 0.30943396226415093\n",
            "F1 Score: 0.3749428440786465\n",
            "\n",
            "CLass p4: \n",
            "Precision: 0.7342386032977691\n",
            "Recall: 0.7356656948493683\n",
            "F1 Score: 0.7349514563106796\n",
            "\n"
          ]
        }
      ],
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy is: ', acc)\n",
        "\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "for i, v in enumerate(['p1' , 'p2' , 'p3' , 'p4']):\n",
        "    print(f\"CLass {v}: \")\n",
        "    print(f\"Precision: {precision[i]}\")\n",
        "    print(f\"Recall: {recall[i]}\")\n",
        "    print(f\"F1 Score: {f1_score[i]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jH0Z8fGd_UX"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETqkmYMfd4o8"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "x = df_encoded.drop(['Approved_Flag'], axis = 1)\n",
        "y = df_encoded['Approved_Flag']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x , y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "dt_model = DecisionTreeClassifier(max_depth = 20, min_samples_split = 10)\n",
        "dt_model.fit(x_train, y_train)\n",
        "y_pred = dt_model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RP-pN8VgRjb",
        "outputId": "8fdf4ead-55ea-4fa9-8069-447c2915fc67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy is:  0.7102103886841793\n",
            "CLass p1: \n",
            "Precision: 0.7176241480038948\n",
            "Recall: 0.7268244575936884\n",
            "F1 Score: 0.7221950024497795\n",
            "\n",
            "CLass p2: \n",
            "Precision: 0.8077221575475358\n",
            "Recall: 0.8251734390485629\n",
            "F1 Score: 0.8163545445631925\n",
            "\n",
            "CLass p3: \n",
            "Precision: 0.3435483870967742\n",
            "Recall: 0.32150943396226417\n",
            "F1 Score: 0.3321637426900585\n",
            "\n",
            "CLass p4: \n",
            "Precision: 0.6542338709677419\n",
            "Recall: 0.630709426627794\n",
            "F1 Score: 0.6422563087580405\n",
            "\n"
          ]
        }
      ],
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy is: ', acc)\n",
        "\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "for i, v in enumerate(['p1' , 'p2' , 'p3' , 'p4']):\n",
        "    print(f\"CLass {v}: \")\n",
        "    print(f\"Precision: {precision[i]}\")\n",
        "    print(f\"Recall: {recall[i]}\")\n",
        "    print(f\"F1 Score: {f1_score[i]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fskWpmr1hYEC"
      },
      "source": [
        "#Having good metrics in XGBOOST, now we do the HYPERPARAMETRIC tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ief-n58XgbCv",
        "outputId": "dbec12f6-faec-4e5a-92a9-30822b6a4d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best  Hyperparameter:  {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size = 0.2, random_state = 42)\n",
        "\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(objective = 'multi:softmax', num_class = 4)\n",
        "\n",
        "\n",
        "## Define the parameter grid for hyperparameter tuning\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators' : [50, 100, 200],\n",
        "    'max_depth' : [3, 5, 7],\n",
        "    'learning_rate' : [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator = xgb_model, param_grid = param_grid, cv = 3, scoring = 'accuracy', n_jobs = -1)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "print('Best  Hyperparameter: ', grid_search.best_params_)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EnmWEGIxqI6m",
        "outputId": "39be4371-b3bc-4b74-e1dd-73c0861058df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.7811719957209081\n"
          ]
        }
      ],
      "source": [
        "## Evaluate the model with the best hyperparameters on the test set\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(x_test, y_test)\n",
        "print('Test Accuracy: ', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF8Zchqm4gwj"
      },
      "source": [
        "# For Better understanding of hyperparameter tuning I am going to use loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3t55CNIQsOlA"
      },
      "outputs": [],
      "source": [
        "## Define the hyperparameter grid\n",
        "\n",
        "param_grid = {\n",
        "        'colsample_bytree' : [0.1, 0.3, 0.5, 0.7, 0.9],\n",
        "        'learning_rate' : [0.001, 0.01, 0.1, 1],\n",
        "        'max_depth' : [3, 5, 8, 10],\n",
        "        'alpha' : [1, 10, 100],\n",
        "        'n_estimators' : [10, 50, 100]\n",
        "}\n",
        "\n",
        "index = 0\n",
        "\n",
        "answers_grid = {\n",
        "        'combination' : [],\n",
        "        'train_accuracy' : [],\n",
        "        'test_accuracy' : [],\n",
        "        'colsample_bytree' : [],\n",
        "        'learning_rate' : [],\n",
        "        'max_depth' : [],\n",
        "        'alpha' : [],\n",
        "        'n_estimators' : []\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sg0RwrI76gKR",
        "outputId": "edbdedc3-f080-4dbf-f1d7-451c2dde43fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum test accuracy is : 0.7739213122548437\n",
            "Maximum_train_accuracy is: 0.7867522510475171\n"
          ]
        }
      ],
      "source": [
        "for colsample_bytree in param_grid['colsample_bytree']:\n",
        "    for learning_rate in param_grid['learning_rate']:\n",
        "        for max_depth in param_grid['max_depth']:\n",
        "            for alpha in param_grid['alpha']:\n",
        "                for n_estimators in param_grid['n_estimators']:\n",
        "                    index = index + 1\n",
        "\n",
        "                    model = xgb.XGBClassifier(\n",
        "                        objective = 'mulit : softmax',\n",
        "                        num_class = 4,\n",
        "                        colsample_bytree = colsample_bytree,\n",
        "                        learning_rate = learning_rate,\n",
        "                        max_depth = max_depth,\n",
        "                        alpha = alpha,\n",
        "                        n_estimators = n_estimators\n",
        "                    )\n",
        "\n",
        "                    y = df_encoded['Approved_Flag']\n",
        "                    x = df_encoded.drop(['Approved_Flag'], axis = 1)\n",
        "\n",
        "                    label_encoder = LabelEncoder()\n",
        "                    y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "                    x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size = 0.2, random_state = 42)\n",
        "\n",
        "                    model.fit(x_train, y_train)\n",
        "\n",
        "                    y_pred_train = model.predict(x_train)\n",
        "                    y_pred_test = model.predict(x_test)\n",
        "\n",
        "                    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "                    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "                    answers_grid['combination'].append(index)\n",
        "                    answers_grid['train_accuracy'].append(train_accuracy)\n",
        "                    answers_grid['test_accuracy'].append(test_accuracy)\n",
        "                    answers_grid['colsample_bytree'].append(colsample_bytree)\n",
        "                    answers_grid['learning_rate'].append(learning_rate)\n",
        "                    answers_grid['max_depth'].append(max_depth)\n",
        "                    answers_grid['alpha'].append(alpha)\n",
        "                    answers_grid['n_estimators'].append(n_estimators)\n",
        "\n",
        "\n",
        "                    # print(f'Combination {index}')\n",
        "                    # print(f'colsample_bytree: {colsample_bytree}, learning_rate: {learning_rate}, max_depth = {max_depth}, alpha: {alpha}, n_estimators : {n_estimators}')\n",
        "                    # print(f'Train Accuracy: {train_accuracy}')\n",
        "                    # print(f'Test_accuracy: {test_accuracy}')\n",
        "                    # print('-'*30)\n",
        "\n",
        "\n",
        "print(f'Maximum test accuracy is : {test_accuracy.max()}')\n",
        "print(f'Maximum_train_accuracy is: {train_accuracy.max()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-mlmus9L0AQq",
        "outputId": "c6ab1c8b-042b-4f3c-c751-43a405a12dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "install: missing destination file operand after 'openpyxl'\n",
            "Try 'install --help' for more information.\n"
          ]
        }
      ],
      "source": [
        "!pip3= install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oi4hfBTW_D71"
      },
      "outputs": [],
      "source": [
        "accuracy_dataset = pd.DataFrame(answers_grid)\n",
        "df.to_excel(excel_writer = \"/content/accuracy.xlsx\", engine = 'openpyxl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHx5eBKizipu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1g6y59MqGzFavOYTX752x83WDAVLiMZoN",
      "authorship_tag": "ABX9TyPcK/t6UioFeEl8OOC8QbAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}